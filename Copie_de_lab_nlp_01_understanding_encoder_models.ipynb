{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benoitmialet/Statistical-and-data-analysis-using-R-/blob/main/Copie_de_lab_nlp_01_understanding_encoder_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa367622",
      "metadata": {
        "id": "aa367622"
      },
      "source": [
        "# LAB NLP 01 Understanding encoder models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0309547",
      "metadata": {
        "id": "b0309547",
        "outputId": "023a6a59-17fd-431f-a288-8bc46ba8a4a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/app\n"
          ]
        }
      ],
      "source": [
        "# cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "925d8e25",
      "metadata": {
        "id": "925d8e25"
      },
      "source": [
        "## Intro"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db7bcffd",
      "metadata": {
        "id": "db7bcffd"
      },
      "source": [
        "In this lab session we are going to use our first transformer model!\n",
        "\n",
        "Before using any model for inference or training, understanding its basic structure and functioning is required. This is the objective of this lab. In the next one, we will work on Natural Language Processing tasks, where transformer models have shown outstading results since several years.\n",
        "\n",
        "We will first focus on Encoder-only models in this first lab. Then, we will tackle Encoder-Decoder models and Decoder-only models in next labs.\n",
        "\n",
        "All along the labs, we will massively use Hugging Face Hub and Hugging Face libraries to try out different transformer models.\n",
        "* **Hugging Face Hub** is a huge storage for Open Source models: https://huggingface.co/models. Anyone can upload a model, with public or private access. A search bar allow to add filters to make models exploration easier: model tasks, languages (NLP), licenses, etc.\n",
        "* **Hugging Face librairies** offer a all-in-one implementation that allow to use any model from the Hub, providing your hardware can handle it: https://huggingface.co/docs. By using a quite simple syntax, you will be able to perform any NLP tasks. We will essentially use Transformers and Datasets libraries in this purpose.\n",
        "\n",
        "Note: at any moment, if you face an \"out of memory\" error, just reset the notebook kernel. It is also recommended to reset the notebook kernel each time you load another model, to avoid memory crash. If you face a memory crash, your virtual system could freeze. In this case, stop your container on docker desktop then restart it if you work locally, or simply reset your Google colab if you're online."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19e8146b",
      "metadata": {
        "id": "19e8146b"
      },
      "source": [
        "## Discovering BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a68ac602",
      "metadata": {
        "id": "a68ac602"
      },
      "source": [
        "The best example to begin with NLP encoder models is BERT (Google, 2018).\n",
        "As a reminder, BERT encoder has been trained for masked language modeling (MLM) task in English language, which makes him good at feature extraction, that's to say good at extracting the semantic meaning of a text and the information it contains (in English).\n",
        "\n",
        "\n",
        "First thing to do before trying to use a transformer model is to understand how it works. Go to the BERT model page then read the text : https://huggingface.co/google-bert/bert-base-uncased/. See how this one is well documented!\n",
        "\n",
        "\n",
        "Next, you have to check the main model files on the \"Files and versions\" tab and understand their purpose. **To use NLP models, you will basically need these files:**\n",
        "\n",
        "* **config.json** shows model parameters configuration.\n",
        "\n",
        "* **tokenizer_config.json** indicates the max length of inputs you can feed the model with. It's one of the most important information. So, keep in mind \"**512** tokens\".\n",
        "\n",
        "* **tokenizer.json** is the most important file. It contains all the vocabulary and the mapping between token and their ids. It also contains all the special tokens. You had to read them carefully\n",
        "\n",
        "* **vocab.txt** references all the tokens of the vocabulary.\n",
        "\n",
        "* At least 1 model file. Most of the time, several model file types are available in the files folder. Each of them contains all the weights of the model. You don't need to download all of them. You have to pick at least one of them. Most common types are:\n",
        "  * **pytorch_model.bin** is the standard binary format (pickle). All model repositories contain this version.\n",
        "  * **model.safetensors** is a cool format created by Hugging Face. It is faster to load, especially on cpu. Another cool feature displays all the model layers just by clicking on the little icon on the hub, next to the file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "720c6077",
      "metadata": {
        "id": "720c6077"
      },
      "source": [
        "## Loading the model on device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b79bc1fb",
      "metadata": {
        "id": "b79bc1fb"
      },
      "source": [
        "All methods that are used in the lab are in the next cell. If you lose one, reload the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a858f871",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a858f871",
        "outputId": "b53e750d-73b8-4175-e5e6-c6376a7f523a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from transformers import (\n",
        "    AutoConfig, BertConfig,\n",
        "    AutoTokenizer,\n",
        "    AutoModel, AutoModelForMaskedLM, BertForMaskedLM,\n",
        "    pipeline\n",
        ")\n",
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# model_path = \"homedata/models/llm_encoders/distilbert-base-uncased\"\n",
        "# model_path = \"homedata/models/llm_encoders/camembert-base/\"\n",
        "# model_path = \"homedata/models/llm_encoders/xlm-roberta-base\"\n",
        "\n",
        "# this line of code will be useful in any of your projects, to check GPU availability\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "456644a9",
      "metadata": {
        "id": "456644a9"
      },
      "source": [
        "`AutoModel` class can load any model if a model name or path is provided. It automatically identifies model type and loads it, thanks to `from_pretrained()` method. This method has plenty of optional parameters than can be found on the documentation, or with `help(AutoModel.from_pretrained)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8977f4cb",
      "metadata": {
        "id": "8977f4cb"
      },
      "outputs": [],
      "source": [
        "help(AutoModel.from_pretrained)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2846f5c",
      "metadata": {
        "id": "b2846f5c"
      },
      "source": [
        "There are plenty of methods to load one specific type of model. However, most of the time, AutoModel high-level class works perfectly to load any model from the hub.\n",
        "\n",
        "There are two options to load files from the Hub:\n",
        "1. Download them locally using `git clone`, `wget`... and provide the directory path to the import method.\n",
        "2. Provide the `model_id` to the same import method. `model_id` is simply the `author_account/model_name` reference displayed on the hub (*e.g.* \"google-bert/bert-base-uncased\"). The model will be downloaded in a cache directory, then loaded in RAM or vRAM.\n",
        "\n",
        "`AutoModel.from_pretrained()` method can be used like this:\n",
        "* `use_safetensors` allows to load model with safetensor files. You can also load tensorflow version, etc.\n",
        "* the `to()` method moves the data in a specific device (cpu, gpu). Be careful: **model and input data MUST be on the same device**. tokenizer stays on cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd521e0f",
      "metadata": {
        "id": "dd521e0f"
      },
      "outputs": [],
      "source": [
        "model_id = \"google-bert/bert-base-uncased\"\n",
        "bert_model = AutoModel.from_pretrained(model_id, use_safetensors=True).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59f9eb16",
      "metadata": {
        "id": "59f9eb16"
      },
      "source": [
        "WARNING: During the model loading, if a warning message states that some layer were randomly initialized, unfortunately the model is not correctly automatically recognized. You will need to use a specific import class, unless you do it on purpose, for instance to initialize a new layer and train it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87a016cd",
      "metadata": {
        "id": "87a016cd"
      },
      "source": [
        "Looking at BERT architecture, we observe:\n",
        "* The **embedding** part, that output token embedding.\n",
        "* The **\"body\"**, that update token embeddings (feature extraction), with 12 blocks (\"Layers\"), each containing several attention heads\n",
        "* The **\"head\"**, That in this case pool the token embedding into 1 single vector, with only 1 pooler layer.\n",
        "\n",
        "Note: model body can be seen as a drill, ad the head as a drill bit. For a same body, an infinite variety of heads can be trained. **Body does the feature extraction and head does the model task**. Task can be pooling, pooling + classification, or anything else."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e4abf11",
      "metadata": {
        "id": "6e4abf11",
        "outputId": "63168bf5-a673-4b18-81cc-731404ef1b86"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bd62f16",
      "metadata": {
        "id": "1bd62f16"
      },
      "source": [
        "More details can be found, like the number of attention head per decoder block, by loading model config file, or directly by checking `config.json` file.\n",
        "`AutoConfig` is a generalist loader like `AutoModel` or `AutoTokenizer` and can detect the model type. `BertConfig` is a specialist loader that  will work only for BERT architecture models. Both `AutoConfig` and `BertConfig` will return the same object with our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13102e00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13102e00",
        "outputId": "e3e25108-10ad-4e6f-d994-b693261560d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertConfig {\n",
            "  \"_name_or_path\": \"google-bert/bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.42.4\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoConfig, BertConfig\n",
        "config = AutoConfig.from_pretrained(model_id)\n",
        "print(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3d34dda",
      "metadata": {
        "id": "c3d34dda"
      },
      "source": [
        "## Using a Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9ffa3ff",
      "metadata": {
        "id": "d9ffa3ff"
      },
      "source": [
        "Tokenization is the first step of processing input data (text), before converting it into a numeric format.\n",
        "\n",
        "Each model family (e.g. BERT) has its own tokenizer, so you will have better to identify which tokenizer or how tokenizer works for each model.\n",
        "\n",
        "3 main tokenization techniques exist\n",
        "* Character tokenization: splitting text into characters\n",
        "* Word tokenization: splitting text into words\n",
        "* **Subword tokenization**: splitting text into word or smaller entities. It combines best aspects of word and character tokenization and is now broadly adopted.\n",
        "\n",
        "N.B.: Word and Subword tokenizers themselves are trained along the model training process, with the same text corpus.\n",
        "N.B.: Today, Subword tokenization is the main technique used in most NLP models.\n",
        "\n",
        "--"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "703085a0",
      "metadata": {
        "id": "703085a0"
      },
      "source": [
        "Tokenizer must be imported in an object apart from the model object, to prepare input data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12977b14",
      "metadata": {
        "id": "12977b14"
      },
      "source": [
        "`AutoTokenizer.from_pretrained()` method automatically detects the type of tokenizer a model use, just by provinding it's path or model_id.\n",
        "if we print the tokenizer we will access to all the important details. Let's have a look:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b3e17e8",
      "metadata": {
        "id": "0b3e17e8"
      },
      "source": [
        "### WordPiece Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48b88209",
      "metadata": {
        "id": "48b88209"
      },
      "source": [
        "WordPiece Tokenizer is generally used by models focusing on 1 language, mostly English, but it can be another european language too. Examples: BERT, DistilBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d4d6749",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d4d6749",
        "outputId": "9e3b58a0-ae2c-4dc0-fa64-c2b3edc241e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertTokenizerFast(name_or_path='distilbert/distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
              "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "model_id = \"distilbert/distilbert-base-uncased\"\n",
        "dbert_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "dbert_tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6570b131",
      "metadata": {
        "id": "6570b131"
      },
      "source": [
        "some characteristics, like the vocabulary size, and plenty others can be found using `help()`. That's where the WordPiece type of tokenizer appears"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "463dc3a3",
      "metadata": {
        "id": "463dc3a3"
      },
      "outputs": [],
      "source": [
        "help(dbert_tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3d0e164",
      "metadata": {
        "id": "f3d0e164"
      },
      "source": [
        "#### Special tokens\n",
        "\n",
        "Special tokens are particular cases, not always related to words. They have to be known to understand tokenization. Special tokens differs from a model to another. Here we take a WordPiece tokenizer as example. Here are the special tokens:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ae0725e",
      "metadata": {
        "id": "1ae0725e"
      },
      "source": [
        "* [CLS] is the Classification token. It is put at the beginning of input sequence, and will be used if the model task is classification (the rest of the sequence is discarded). It integrates the global context of the sequence\n",
        "* [SEP] is the separator token. It delimitates where sentences end up in a sequence. It also marks the end of the input sequence.\n",
        "* [UKN] is the unknown token. It is used to handle words or subwords that are not in the model's vocabulary\n",
        "* [PAD] is the padding token. When providing a batch of multiple samples as input in the model, all the tensors must have the same size. A max_size is set (by default or manually), and all sequences shortest than this will be completed by this token.\n",
        "* [MASK] is the mask token. It is randomly put in a sequence if the model is being trained for Masked Language Modeling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee438e28",
      "metadata": {
        "id": "ee438e28"
      },
      "source": [
        "Let's tokenize a sentence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dec7d57f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dec7d57f",
        "outputId": "14af3378-edcc-4e95-c735-584a6d801e26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'token', '##izing', 'text', 'is', 'a', 'core', 'task', 'in', 'nl', '##p', '.', '[SEP]']\n"
          ]
        }
      ],
      "source": [
        "text = \"tokenizing text is a core task in NLP.\"\n",
        "\n",
        "tokens = dbert_tokenizer(text)\n",
        "\n",
        "print(tokens.tokens())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c819ac4",
      "metadata": {
        "id": "4c819ac4"
      },
      "source": [
        "We can see [CLS], [SEP] and some tokens beginning by `##`, which indicates they are subword tokens, which are linked to the previous token.\n",
        "\n",
        "We can also observe that each token has its own mapped id in the tokenizer vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f06c444",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "4f06c444",
        "outputId": "f9b9316b-4bf9-4bd3-8cda-77ebaa211886"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      token     id\n",
              "0     [CLS]    101\n",
              "1     token  19204\n",
              "2   ##izing   6026\n",
              "3      text   3793\n",
              "4        is   2003\n",
              "5         a   1037\n",
              "6      core   4563\n",
              "7      task   4708\n",
              "8        in   1999\n",
              "9        nl  17953\n",
              "10      ##p   2361\n",
              "11        .   1012\n",
              "12    [SEP]    102"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78160cf4-bbdd-4a18-928d-29a55aeb7df0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[CLS]</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>token</td>\n",
              "      <td>19204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>##izing</td>\n",
              "      <td>6026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>text</td>\n",
              "      <td>3793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>is</td>\n",
              "      <td>2003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>a</td>\n",
              "      <td>1037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>core</td>\n",
              "      <td>4563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>task</td>\n",
              "      <td>4708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>in</td>\n",
              "      <td>1999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>nl</td>\n",
              "      <td>17953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>##p</td>\n",
              "      <td>2361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>.</td>\n",
              "      <td>1012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[SEP]</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78160cf4-bbdd-4a18-928d-29a55aeb7df0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-78160cf4-bbdd-4a18-928d-29a55aeb7df0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-78160cf4-bbdd-4a18-928d-29a55aeb7df0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6844ea67-6014-422b-aae9-86c71ba3aafc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6844ea67-6014-422b-aae9-86c71ba3aafc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6844ea67-6014-422b-aae9-86c71ba3aafc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 13,\n  \"fields\": [\n    {\n      \"column\": \"token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \".\",\n          \"nl\",\n          \"[CLS]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6303,\n        \"min\": 101,\n        \"max\": 19204,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          1012,\n          17953,\n          101\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame({'token': tokens.tokens(), 'id': tokens.input_ids})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e212c6ef",
      "metadata": {
        "id": "e212c6ef"
      },
      "source": [
        "### SentencePiece tokenizer (XLM-RoBERTa)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6e3302e",
      "metadata": {
        "id": "f6e3302e"
      },
      "source": [
        "SentencePiec Tokenizer is generally (not exclusively) used by models that can handle multiple languages, including non european languages. Examples: mBERT, XLM-RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b332c5a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b332c5a2",
        "outputId": "7e1185cc-7846-4146-bb0d-9db417da6593"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaTokenizerFast(name_or_path='FacebookAI/xlm-roberta-base', vocab_size=250002, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
              "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t250001: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "model_id = \"FacebookAI/xlm-roberta-base\"\n",
        "xlmroberta_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "xlmroberta_tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9e4d0dc",
      "metadata": {
        "id": "c9e4d0dc"
      },
      "source": [
        "Here, we see different special tokens, but thanks to the `special_tokens` dictionnary, we can understand that classification. For instance, BOS and SEP tokens are now become `<s>` and `</s>`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20a29b28",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20a29b28",
        "outputId": "08e239ac-a06a-46b1-ccaf-104f19bf64d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s>', '▁to', 'ken', 'izing', '▁text', '▁is', '▁a', '▁core', '▁task', '▁in', '▁N', 'LP', '.', '</s>']\n"
          ]
        }
      ],
      "source": [
        "text = \"tokenizing text is a core task in NLP.\"\n",
        "\n",
        "tokens = xlmroberta_tokenizer(text)\n",
        "\n",
        "print(tokens.tokens())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "399f8442",
      "metadata": {
        "id": "399f8442"
      },
      "source": [
        "Now it's a different situation as for WordPiece. Tokens corresponding to the beginning of a word starts with `_`, and those who are linked to the previous one don't. The SentencePiece tokenizer is agnostic to accents, ponctuation, and is more adappted to languages without whitespaces, like Japanese."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b14c3bc2",
      "metadata": {
        "id": "b14c3bc2"
      },
      "source": [
        "## Understanding BERT model input and output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09407fc8",
      "metadata": {
        "id": "09407fc8"
      },
      "source": [
        "Let's use the famous BERT model and try to understand the output data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cf70d3e",
      "metadata": {
        "id": "6cf70d3e"
      },
      "source": [
        "### Tokenization (input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58dd7ee0",
      "metadata": {
        "id": "58dd7ee0"
      },
      "outputs": [],
      "source": [
        "model_id = \"google-bert/bert-base-uncased\"\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eec22feb",
      "metadata": {
        "id": "eec22feb"
      },
      "source": [
        "Tokenized data can be retruned in many formats. We will use pytorch one.\n",
        "\n",
        "Don't forget to move tokenized data, which will be model input data, on the device as the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f3fd686",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f3fd686",
        "outputId": "4ae50090-e489-46c8-ccc0-f34044b4a92f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  1045,  4553, 17953,  2361,  1012,  2009,  1005,  1055,  1037,\n",
              "          3255, 10126,  1012,  2009,  2003,  2061,  2524,   999,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "text = \"I learn NLP. It's a pain everyday. It is so hard!\"\n",
        "tokens = bert_tokenizer(text, return_tensors='pt').to(device)\n",
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36619604",
      "metadata": {
        "id": "36619604"
      },
      "source": [
        "`token_type_ids` `attention_mask` and are used for training. We will not use them in the lab. For your information:\n",
        "* `token_type_ids` differenciates different contexts, such as the question and answer part.\n",
        "* `attention_mask` will indicate which token are masked (for MLM training)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c014f56e",
      "metadata": {
        "id": "c014f56e"
      },
      "source": [
        "We see some special tokens (101, 102) among them. Let's decode them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1ec0bd2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "c1ec0bd2",
        "outputId": "fabf7b15-96f7-45f7-8fdc-54c6ec1c33af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[CLS] i learn nlp. it's a pain everyday. it is so hard! [SEP]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "bert_tokenizer.decode(tokens.input_ids.squeeze())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1fa322f",
      "metadata": {
        "id": "a1fa322f"
      },
      "source": [
        "### Output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a604298",
      "metadata": {
        "id": "4a604298"
      },
      "source": [
        "Before using a model for inference, puting code in a `torch.no_grad()` context will avoid computing gradients for nothing. It can be a big deal if you are working with big models, or on cpu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f89df7f2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f89df7f2",
        "outputId": "27c65571-cda3-4c4c-d0af-4cf7180ba801"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "218 ms ± 62.5 ms per loop (mean ± std. dev. of 10 runs, 5 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 5 -r 10\n",
        "output = bert_model(tokens.input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cce9c7e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cce9c7e",
        "outputId": "2938df53-139c-4eeb-b889-c33a0787f356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128 ms ± 29.4 ms per loop (mean ± std. dev. of 10 runs, 5 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 5 -r 10\n",
        "with torch.no_grad():\n",
        "    output = bert_model(tokens.input_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfc8b80c",
      "metadata": {
        "id": "bfc8b80c"
      },
      "source": [
        "Reminder: encoder model are build in two parts:\n",
        "* A **\"body\"** for feature extraction, with several blocks, each containing several attention heads\n",
        "* A **\"head\"** for classification (or anything else), pooling\n",
        "\n",
        "So, model output provides body and head outputs.\n",
        "* body output is given by `last_hidden_state` attribute\n",
        "* head output is given by `pooler_output`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f71acbd5",
      "metadata": {
        "id": "f71acbd5"
      },
      "outputs": [],
      "source": [
        "output = bert_model(tokens.input_ids)\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c04b4b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c04b4b9",
        "outputId": "85801b85-2abc-469e-b15e-c9f17c96af12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 19, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "output.last_hidden_state.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "121fe701",
      "metadata": {
        "id": "121fe701"
      },
      "source": [
        "last_hidden_state corresponds to extracted text context.\n",
        "\n",
        "Dimensions are:\n",
        "* batch size (here, 1 sentence)\n",
        "* input sequence length (1 vector per token)\n",
        "* embedding size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb9498db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb9498db",
        "outputId": "3d55e9b6-4f90-4fae-97a2-5bc976152600"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "output.pooler_output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc5eb2ef",
      "metadata": {
        "id": "bc5eb2ef"
      },
      "source": [
        "pooler_output always has the same dimension. This layer is trained to \"pool\" hidden state matrix in one single vector.\n",
        "This vector carries the text context and can be used for other purposes such as sentence similarity or text classification.\n",
        "\n",
        "Dimensions are:\n",
        "* batch size (here, 1 sentence)\n",
        "* embedding size"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74acf4bc",
      "metadata": {
        "id": "74acf4bc"
      },
      "source": [
        "Hugging Face Transformers can also provide all decoder blocks outputs and their attention matrices:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b471c976",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b471c976",
        "outputId": "48031759-a8d2-4bc2-ecc8-858da20ccad3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
          ]
        }
      ],
      "source": [
        "output = bert_model(\n",
        "    tokens.input_ids,\n",
        "    output_hidden_states=True,\n",
        "    output_attentions=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26c2745d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26c2745d",
        "outputId": "eec94121-bf94-4c41-e22e-5648e390e2f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 13\n"
          ]
        }
      ],
      "source": [
        "print(len(output.attentions), len(output.hidden_states))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42849fbf",
      "metadata": {
        "id": "42849fbf"
      },
      "source": [
        "## Masked Language Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "658822e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "658822e9",
        "outputId": "c0250fbd-eb12-4eff-ba86-05a2562e4e38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'XXXXXXXXXXXXXXXXXXXXXXXXXX'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "\"XXXXXXXXXXXXXXXXXXXXXXXXXX\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88cca33d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88cca33d",
        "outputId": "f0dc3d29-d719-446d-f6c6-d7fc484fa9d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForMaskedLM, BertForMaskedLM\n",
        "model_id = \"google-bert/bert-base-uncased\"\n",
        "bert_model_mlm = BertForMaskedLM.from_pretrained(model_id).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e603c583",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "e603c583",
        "outputId": "55f48741-0c45-4d63-af7c-be6f4f9a0bfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[CLS] i learn nlp. it's a pain everyday. it is so [MASK]! [SEP]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "text = \"I learn NLP. It's a pain everyday. It is so [MASK]!\"  #original masked token: \"hard\"\n",
        "tokens = bert_tokenizer(text, return_tensors='pt').input_ids.to(device)\n",
        "bert_tokenizer.decode(tokens.squeeze())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3154616c",
      "metadata": {
        "id": "3154616c"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    output = bert_model_mlm(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8e21608",
      "metadata": {
        "id": "a8e21608"
      },
      "source": [
        "Let's check what MLM output looks like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03d872be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03d872be",
        "outputId": "c1f435d1-3b74-4a9a-f655-e8f5dc50eb64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MaskedLMOutput(loss=None, logits=tensor([[[ -6.7952,  -6.7584,  -6.7695,  ...,  -6.1543,  -5.9597,  -4.0777],\n",
              "         [-13.2081, -12.6957, -12.8394,  ..., -11.5705,  -9.7691, -12.9378],\n",
              "         [ -7.6904,  -7.9168,  -7.8124,  ...,  -7.7851,  -5.8529,  -6.5248],\n",
              "         ...,\n",
              "         [ -5.1325,  -5.0025,  -5.0526,  ...,  -5.0298,  -4.9050,  -3.2654],\n",
              "         [-10.0085, -10.0155, -10.3207,  ...,  -9.8141,  -8.8576,  -4.7096],\n",
              "         [-14.5361, -14.9923, -14.8336,  ..., -14.0959, -11.2791,  -9.7337]]]), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "551044cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "551044cd",
        "outputId": "a2b12882-a7da-4042-bb00-4d3210f0d90e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 19, 30522])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "output.logits.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "854ddad1",
      "metadata": {
        "id": "854ddad1"
      },
      "source": [
        "It seems there is 1 vector of 30522 values for each of the tokens. These are the logits (the scores) for each token of the vocabulary. The logits that interest us are the logits for the [MASK] token that BERT learned to fill.\n",
        "\n",
        "Let's parse the logits for each of the vectors and get each time the token with the highest probability. We will see what the model filled instead of the [MASK] token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11222cbc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "11222cbc",
        "outputId": "5cc96605-690b-42cf-faab-a15e05c995a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\". i learn nlp. it's a pain everyday. it is so hard!.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "id_list = [torch.argmax(logit) for logit in output.logits.squeeze()]\n",
        "bert_tokenizer.decode(id_list, clean_up_tokenization_spaces=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "733f8fc9",
      "metadata": {
        "id": "733f8fc9"
      },
      "source": [
        "#### Using Transformers pipe"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83464755",
      "metadata": {
        "id": "83464755"
      },
      "source": [
        "Transformers `pipeline()` is a high level method that allow to to almost any task from any transformer model found in the Hub, with a single liner. It is very practicle to quickly try out some models or build POCs (prooves of concept)\n",
        "\n",
        "https://huggingface.co/docs/transformers/main/en/quicktour#pipeline\n",
        "\n",
        "More detailed documentation: https://huggingface.co/docs/transformers/main/en/main_classes/pipelines\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9564308d",
      "metadata": {
        "id": "9564308d",
        "outputId": "19d5042b-466f-40d6-e45b-f165c95dfa10"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at homedata/models/llm_encoders/bert-base-uncased/ were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "pipe = pipeline(model=model_path, task='fill-mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96364a90",
      "metadata": {
        "id": "96364a90"
      },
      "source": [
        "Let's try to do the same thing as before with only one line of code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbd3e6f8",
      "metadata": {
        "id": "dbd3e6f8",
        "outputId": "fef91dec-c911-44ae-90f0-c878f341a82c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'score': 0.11025796085596085,\n",
              "  'token': 2524,\n",
              "  'token_str': 'hard',\n",
              "  'sequence': \"i learn nlp. it's a pain everyday. it is so hard!\"},\n",
              " {'score': 0.07964936643838882,\n",
              "  'token': 2204,\n",
              "  'token_str': 'good',\n",
              "  'sequence': \"i learn nlp. it's a pain everyday. it is so good!\"},\n",
              " {'score': 0.054610494524240494,\n",
              "  'token': 9145,\n",
              "  'token_str': 'painful',\n",
              "  'sequence': \"i learn nlp. it's a pain everyday. it is so painful!\"},\n",
              " {'score': 0.03537808358669281,\n",
              "  'token': 3733,\n",
              "  'token_str': 'easy',\n",
              "  'sequence': \"i learn nlp. it's a pain everyday. it is so easy!\"},\n",
              " {'score': 0.03381006792187691,\n",
              "  'token': 2919,\n",
              "  'token_str': 'bad',\n",
              "  'sequence': \"i learn nlp. it's a pain everyday. it is so bad!\"}]"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"I learn NLP. It's a pain everyday. It is so [MASK]!\"  #original masked token: hard\n",
        "pipe(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ede1748",
      "metadata": {
        "id": "9ede1748"
      },
      "source": [
        "## Use BERT output for Sentence similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "852af607",
      "metadata": {
        "id": "852af607"
      },
      "outputs": [],
      "source": [
        "text1 = \"Replace me by any text you'd like.\"\n",
        "encoded_input = bert_tokenizer(text, return_tensors='pt').to(device)\n",
        "output = bert_model(**encoded_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4b0fe0e",
      "metadata": {
        "id": "f4b0fe0e",
        "outputId": "09b167f5-405c-4347-d75b-116373c28ae6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text1 = output.pooler_output.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9cfb2ce",
      "metadata": {
        "id": "e9cfb2ce"
      },
      "outputs": [],
      "source": [
        "def embed_text(text, model, tokenizer, device):\n",
        "    encoded_input = tokenizer(text, return_tensors='pt').to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(**encoded_input)\n",
        "    embedding = output.pooler_output.squeeze()\n",
        "\n",
        "    return embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "348d4af9",
      "metadata": {
        "id": "348d4af9"
      },
      "outputs": [],
      "source": [
        "text1 = \"I liked this movie very much\"\n",
        "text2 = \"This movie is one oof the best I've seen\"\n",
        "vector1 = embed_text(text1, bert_model, bert_tokenizer, device)\n",
        "vector2 = embed_text(text2, bert_model, bert_tokenizer, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "316f5ed3",
      "metadata": {
        "id": "316f5ed3",
        "outputId": "9f3349af-abc9-423d-9ed6-dff03a3108b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.9423], device='cuda:0')"
            ]
          },
          "execution_count": 187,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.nn.functional import cosine_similarity\n",
        "\n",
        "cosine_similarity(vector1.unsqueeze(0), vector2.unsqueeze(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2999db73",
      "metadata": {
        "id": "2999db73",
        "outputId": "b4554caa-0a08-4e17-c954-b4b11c9733a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{\"This movie is one of the best I've seen\": 0.9913552403450012,\n",
              " 'I like to go to the movie theater': 0.9847801923751831,\n",
              " 'Germany has an access to the open sea': 0.9568362832069397,\n",
              " '5 miles roughly equals 8 kilometers': 0.846796989440918,\n",
              " 'I hate this movie': 0.8964381217956543}"
            ]
          },
          "execution_count": 189,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_reference = \"I liked this movie very much\"\n",
        "text_collection = [\n",
        "    \"This movie is one of the best I've seen\",\n",
        "    \"I like to go to the movie theater\",\n",
        "    \"Germany has an access to the open sea\",\n",
        "    \"5 miles roughly equals 8 kilometers\",\n",
        "    \"I hate this movie\"\n",
        "]\n",
        "vector_reference = embed_text(text_reference, bert_model, bert_tokenizer, device)\n",
        "vector_dict = {text: embed_text(text, bert_model, bert_tokenizer, device) for text in text_collection}\n",
        "{t:float(cosine_similarity(vector_reference.unsqueeze(0), v.unsqueeze(0))) for t,v in vector_dict.items()}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b387b85c",
      "metadata": {
        "id": "b387b85c"
      },
      "source": [
        "## Use Sentence Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab3aacc6",
      "metadata": {
        "id": "ab3aacc6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "530da15a",
      "metadata": {
        "id": "530da15a"
      },
      "source": [
        "# Vizualizing self-attention mechanism"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7bcd503",
      "metadata": {
        "id": "a7bcd503"
      },
      "source": [
        "Check this tutorial on Collab NB :\n",
        "    \n",
        "https://colab.research.google.com/drive/1hXIQ77A4TYS4y3UthWF-Ci7V7vVUoxmQ?usp=sharing#scrollTo=YLAhBxDSScmV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dcb2249",
      "metadata": {
        "id": "2dcb2249"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f5e54380",
      "metadata": {
        "id": "f5e54380"
      },
      "source": [
        "# ---------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df51ae80",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "3ebc23df5c3c46e98d90e7ed9e65087c",
            "02ab137c46394575897d151b716880ba"
          ]
        },
        "id": "df51ae80",
        "outputId": "f7e97293-3876-474e-d6d7-76ae7c85065e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1454: FutureWarning: The repository for subjqa contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/subjqa\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ebc23df5c3c46e98d90e7ed9e65087c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/9.12k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02ab137c46394575897d151b716880ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/21.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "['books', 'electronics', 'grocery', 'movies', 'restaurants', 'tripadvisor']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import get_dataset_config_names\n",
        "domains = get_dataset_config_names(\"subjqa\")\n",
        "domains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5934e864",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "e6583c6faccd40f0bc3d53ab16407870",
            "b98b9ecd3c0b4ebc9e8eeeaf74fd0c2a",
            "f0f7c2fa28aa4daab947d8a0d03b6f3a",
            "52a38e76b2a943feb1ed5fbcfa2d4963"
          ]
        },
        "id": "5934e864",
        "outputId": "b2a08c6e-533d-43af-8b39-108cc09be6c7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6583c6faccd40f0bc3d53ab16407870",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b98b9ecd3c0b4ebc9e8eeeaf74fd0c2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/1295 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0f7c2fa28aa4daab947d8a0d03b6f3a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/358 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52a38e76b2a943feb1ed5fbcfa2d4963",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/255 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "subjqa = load_dataset(\"subjqa\", name=\"electronics\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4857c15",
      "metadata": {
        "id": "c4857c15"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "dfs = {split: dset.to_pandas() for split, dset in subjqa.flatten().items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44c81029",
      "metadata": {
        "id": "44c81029",
        "outputId": "23f48cad-5b01-48ef-fb30-183d21d229d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of questions in train: 1295\n",
            "Number of questions in test: 358\n",
            "Number of questions in validation: 255\n"
          ]
        }
      ],
      "source": [
        "for split, df in dfs.items():\n",
        "    print(f\"Number of questions in {split}: {df['id'].nunique()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61be2a6e",
      "metadata": {
        "id": "61be2a6e",
        "outputId": "425f581a-e067-4726-b536-8251aa245d31"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>question</th>\n",
              "      <th>answers.text</th>\n",
              "      <th>answers.answer_start</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>791</th>\n",
              "      <td>B005DKZTMG</td>\n",
              "      <td>Does the keyboard lightweight?</td>\n",
              "      <td>[this keyboard is compact]</td>\n",
              "      <td>[215]</td>\n",
              "      <td>I really like this keyboard.  I give it 4 star...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1159</th>\n",
              "      <td>B00AAIPT76</td>\n",
              "      <td>How is the battery?</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>I bought this after the first spare gopro batt...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           title                        question                answers.text  \\\n",
              "791   B005DKZTMG  Does the keyboard lightweight?  [this keyboard is compact]   \n",
              "1159  B00AAIPT76             How is the battery?                          []   \n",
              "\n",
              "     answers.answer_start                                            context  \n",
              "791                 [215]  I really like this keyboard.  I give it 4 star...  \n",
              "1159                   []  I bought this after the first spare gopro batt...  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#hide_output\n",
        "qa_cols = [\"title\", \"question\", \"answers.text\",\n",
        "           \"answers.answer_start\", \"context\"]\n",
        "sample_df = dfs[\"train\"][qa_cols].sample(2, random_state=7)\n",
        "sample_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fd01f4d",
      "metadata": {
        "id": "6fd01f4d",
        "outputId": "b15ee4b1-b838-488e-c0a6-685ab7a8757c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>domain</th>\n",
              "      <th>nn_mod</th>\n",
              "      <th>nn_asp</th>\n",
              "      <th>query_mod</th>\n",
              "      <th>query_asp</th>\n",
              "      <th>q_reviews_id</th>\n",
              "      <th>question_subj_level</th>\n",
              "      <th>ques_subj_score</th>\n",
              "      <th>is_ques_subjective</th>\n",
              "      <th>review_id</th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answers.text</th>\n",
              "      <th>answers.answer_start</th>\n",
              "      <th>answers.answer_subj_level</th>\n",
              "      <th>answers.ans_subj_score</th>\n",
              "      <th>answers.is_ans_subjective</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>electronics</td>\n",
              "      <td>great</td>\n",
              "      <td>bass response</td>\n",
              "      <td>excellent</td>\n",
              "      <td>bass</td>\n",
              "      <td>0514ee34b672623dff659334a25b599b</td>\n",
              "      <td>5</td>\n",
              "      <td>0.50</td>\n",
              "      <td>False</td>\n",
              "      <td>882b1e2745a4779c8f17b3d4406b91c7</td>\n",
              "      <td>2543d296da9766d8d17d040ecc781699</td>\n",
              "      <td>B00001P4ZH</td>\n",
              "      <td>I have had Koss headphones in the past, Pro 4A...</td>\n",
              "      <td>How is the bass?</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>electronics</td>\n",
              "      <td>harsh</td>\n",
              "      <td>high</td>\n",
              "      <td>not strong</td>\n",
              "      <td>bass</td>\n",
              "      <td>7c46670208f7bf5497480fbdbb44561a</td>\n",
              "      <td>1</td>\n",
              "      <td>0.50</td>\n",
              "      <td>False</td>\n",
              "      <td>ce76793f036494eabe07b33a9a67288a</td>\n",
              "      <td>d476830bf9282e2b9033e2bb44bbb995</td>\n",
              "      <td>B00001P4ZH</td>\n",
              "      <td>To anyone who hasn't tried all the various typ...</td>\n",
              "      <td>Is this music song have a goo bass?</td>\n",
              "      <td>[Bass is weak as expected, Bass is weak as exp...</td>\n",
              "      <td>[1302, 1302]</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>[0.5083333, 0.5083333]</td>\n",
              "      <td>[True, True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>electronics</td>\n",
              "      <td>neutral</td>\n",
              "      <td>sound</td>\n",
              "      <td>present</td>\n",
              "      <td>bass</td>\n",
              "      <td>8fbf26792c438aa83178c2d507af5d77</td>\n",
              "      <td>1</td>\n",
              "      <td>0.50</td>\n",
              "      <td>False</td>\n",
              "      <td>d040f2713caa2aff0ce95affb40e12c2</td>\n",
              "      <td>455575557886d6dfeea5aa19577e5de4</td>\n",
              "      <td>B00001P4ZH</td>\n",
              "      <td>I have had many sub-$100 headphones from $5 Pa...</td>\n",
              "      <td>How is the bass?</td>\n",
              "      <td>[The only fault in the sound is the bass]</td>\n",
              "      <td>[650]</td>\n",
              "      <td>[2]</td>\n",
              "      <td>[0.6333333]</td>\n",
              "      <td>[True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>electronics</td>\n",
              "      <td>muddy</td>\n",
              "      <td>bass</td>\n",
              "      <td>awesome</td>\n",
              "      <td>bass</td>\n",
              "      <td>9876fd06ed8f075fcad70d1e30e7e8be</td>\n",
              "      <td>1</td>\n",
              "      <td>0.50</td>\n",
              "      <td>False</td>\n",
              "      <td>043e7162df91f6ea916c790c8a6f6b22</td>\n",
              "      <td>6895a59b470d8feee0f39da6c53a92e5</td>\n",
              "      <td>B00001WRSJ</td>\n",
              "      <td>My sister's Bose headphones finally died and s...</td>\n",
              "      <td>How is the audio bass?</td>\n",
              "      <td>[the best of all of them]</td>\n",
              "      <td>[1609]</td>\n",
              "      <td>[1]</td>\n",
              "      <td>[0.3]</td>\n",
              "      <td>[False]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>electronics</td>\n",
              "      <td>perfect</td>\n",
              "      <td>bass</td>\n",
              "      <td>incredible</td>\n",
              "      <td>sound</td>\n",
              "      <td>16506b53e2d4c2b6a65881d9462256c2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.65</td>\n",
              "      <td>True</td>\n",
              "      <td>29ccd7e690050e2951be49289e915382</td>\n",
              "      <td>7a2173c502da97c5bd5950eae7cd7430</td>\n",
              "      <td>B00001WRSJ</td>\n",
              "      <td>Wow. Just wow. I'm a 22 yr old with a crazy ob...</td>\n",
              "      <td>Why do I have an incredible sound?</td>\n",
              "      <td>[The sound is so crisp, crazy obsession with s...</td>\n",
              "      <td>[141, 38]</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>[0.40833333, 0.40833333]</td>\n",
              "      <td>[False, False]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        domain   nn_mod         nn_asp   query_mod query_asp  \\\n",
              "0  electronics    great  bass response   excellent      bass   \n",
              "1  electronics    harsh           high  not strong      bass   \n",
              "2  electronics  neutral          sound     present      bass   \n",
              "3  electronics    muddy           bass     awesome      bass   \n",
              "4  electronics  perfect           bass  incredible     sound   \n",
              "\n",
              "                       q_reviews_id  question_subj_level  ques_subj_score  \\\n",
              "0  0514ee34b672623dff659334a25b599b                    5             0.50   \n",
              "1  7c46670208f7bf5497480fbdbb44561a                    1             0.50   \n",
              "2  8fbf26792c438aa83178c2d507af5d77                    1             0.50   \n",
              "3  9876fd06ed8f075fcad70d1e30e7e8be                    1             0.50   \n",
              "4  16506b53e2d4c2b6a65881d9462256c2                    1             0.65   \n",
              "\n",
              "   is_ques_subjective                         review_id  \\\n",
              "0               False  882b1e2745a4779c8f17b3d4406b91c7   \n",
              "1               False  ce76793f036494eabe07b33a9a67288a   \n",
              "2               False  d040f2713caa2aff0ce95affb40e12c2   \n",
              "3               False  043e7162df91f6ea916c790c8a6f6b22   \n",
              "4                True  29ccd7e690050e2951be49289e915382   \n",
              "\n",
              "                                 id       title  \\\n",
              "0  2543d296da9766d8d17d040ecc781699  B00001P4ZH   \n",
              "1  d476830bf9282e2b9033e2bb44bbb995  B00001P4ZH   \n",
              "2  455575557886d6dfeea5aa19577e5de4  B00001P4ZH   \n",
              "3  6895a59b470d8feee0f39da6c53a92e5  B00001WRSJ   \n",
              "4  7a2173c502da97c5bd5950eae7cd7430  B00001WRSJ   \n",
              "\n",
              "                                             context  \\\n",
              "0  I have had Koss headphones in the past, Pro 4A...   \n",
              "1  To anyone who hasn't tried all the various typ...   \n",
              "2  I have had many sub-$100 headphones from $5 Pa...   \n",
              "3  My sister's Bose headphones finally died and s...   \n",
              "4  Wow. Just wow. I'm a 22 yr old with a crazy ob...   \n",
              "\n",
              "                              question  \\\n",
              "0                     How is the bass?   \n",
              "1  Is this music song have a goo bass?   \n",
              "2                     How is the bass?   \n",
              "3               How is the audio bass?   \n",
              "4   Why do I have an incredible sound?   \n",
              "\n",
              "                                        answers.text answers.answer_start  \\\n",
              "0                                                 []                   []   \n",
              "1  [Bass is weak as expected, Bass is weak as exp...         [1302, 1302]   \n",
              "2          [The only fault in the sound is the bass]                [650]   \n",
              "3                          [the best of all of them]               [1609]   \n",
              "4  [The sound is so crisp, crazy obsession with s...            [141, 38]   \n",
              "\n",
              "  answers.answer_subj_level    answers.ans_subj_score  \\\n",
              "0                        []                        []   \n",
              "1                    [1, 1]    [0.5083333, 0.5083333]   \n",
              "2                       [2]               [0.6333333]   \n",
              "3                       [1]                     [0.3]   \n",
              "4                    [1, 1]  [0.40833333, 0.40833333]   \n",
              "\n",
              "  answers.is_ans_subjective  \n",
              "0                        []  \n",
              "1              [True, True]  \n",
              "2                    [True]  \n",
              "3                   [False]  \n",
              "4            [False, False]  "
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfs['train'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89b59aa9",
      "metadata": {
        "id": "89b59aa9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "dd414918",
      "metadata": {
        "id": "dd414918"
      },
      "source": [
        "# ---------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f8e17f8",
      "metadata": {
        "id": "6f8e17f8",
        "outputId": "70507ea6-6b55-4e25-b6c8-a43e8fb011d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        0       1       2       3\n",
            "Evaluated on           de      fr      it      en\n",
            "Fine-tune on de    0.8677  0.7141  0.6923   0.589\n",
            "Fine-tune on each  0.8677  0.8505  0.8192  0.7068\n",
            "Fine-tune on all   0.8682  0.8647  0.8575   0.787\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Evaluated on': ['de', 'fr', 'it', 'en'],\n",
        "    'Fine-tune on de': [0.8677, 0.7141, 0.6923, 0.5890],\n",
        "    'Fine-tune on each': [0.8677, 0.8505, 0.8192, 0.7068],\n",
        "    'Fine-tune on all': [0.8682, 0.8647, 0.8575, 0.7870]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4855ba09",
      "metadata": {
        "id": "4855ba09"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0c6fa3ef",
      "metadata": {
        "id": "0c6fa3ef"
      },
      "source": [
        "# ---------------"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}